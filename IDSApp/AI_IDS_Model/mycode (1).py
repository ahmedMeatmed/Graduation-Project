# -*- coding: utf-8 -*-
"""MyCode.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MEDzX4Se1Z5ZpCabBnrqbXCcS15B35aT
"""

from plotly.subplots import make_subplots
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')
pd.set_option('display.max_columns', None)

"""### **1ï¸âƒ£ Load Data**"""

df = pd.read_csv("cleaned_network_data.csv")

"""### **2ï¸âƒ£ Explore Data**"""

df.head()

def full_report(df):
    dtypes = df.dtypes
    n_unique = df.nunique()
    u_ratio = ((n_unique / len(df)) * 100).round(2).astype(str) + '%'
    nulls = df.isnull().sum()
    n_ratio = ((nulls / len(df)) * 100).round(2).astype(str) + '%'
    mod_or_mean = []
    for col in df.columns:
        if pd.api.types.is_numeric_dtype(df[col]):
            try:
                mean_val = df[col].mean()
                mod_or_mean.append(f"mean = {round(mean_val, 2)}")
            except:
                mod_or_mean.append("mean = NaN")
        else:
            try:
                mode_val = df[col].mode().iloc[0]
                mod_or_mean.append(f"mode = {mode_val}")
            except:
                mod_or_mean.append("mode = NaN")
    full_report_df = pd.DataFrame({'DTypes': dtypes,'N_Uniq': n_unique,'U Ratio': u_ratio,'Nulls': nulls,'N_Ratio': n_ratio,'Mode or Mean': mod_or_mean})
    print(f"{'*'*50}")
    print(f'Empty Rows: {df.isnull().all(axis=1).sum()}')
    print(f'Empty Columns: {df.isnull().all(axis=0).sum()}')
    print(f'Duplicate Rows: {df.duplicated().sum()}')
    print(f'Number of Rows: {df.shape[0]}')
    print(f'Number of Columns: {df.shape[1]}')
    print(f"{'*'*50}")
    return full_report_df

full_report(df)

"""### **3ï¸âƒ£ Clean the Data**

- Drop Nulls ROWs
"""

df = df.dropna()

cols_numeric = ["Dst Port", "Protocol", "PacketSize", "PacketCount", "PayloadSize", "FlowDirection", "TcpFlags"]

for col in cols_numeric:
    df[col] = pd.to_numeric(df[col], errors="coerce")

df["Dst Port"].fillna(df["Dst Port"].mode()[0], inplace=True)
df["Protocol"].fillna(df["Protocol"].mode()[0], inplace=True)
df["PacketCount"].fillna(df["PacketCount"].median(), inplace=True)
df["TcpFlags"].fillna(df["TcpFlags"].mode()[0], inplace=True)
df["FlowDirection"].fillna(df["FlowDirection"].median(), inplace=True)
df["PacketSize"].fillna(df["PacketSize"].median(), inplace=True)
df["PayloadSize"].fillna(df["PayloadSize"].median(), inplace=True)

df["Dst Port"] = df["Dst Port"].astype("int64")
df["Protocol"] = df["Protocol"].astype("int64")
df["PacketCount"] = df["PacketCount"].astype("int64")
df["TcpFlags"] = df["TcpFlags"].astype("int64")

full_report(df)

"""- Drop Duplicate Columns"""

#Drop Duplicate Columns
df.drop_duplicates(inplace=True)

df["IsMalicious"].value_counts()

"""### **8ï¸âƒ£ Split Data**"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

features = ["Dst Port", "Protocol", "PacketSize", "PacketCount",
            "PayloadSize", "FlowDirection", "TcpFlags"]

X = df[features]
y = df["IsMalicious"]

"""### **9ï¸âƒ£ Scalling**"""

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_normal = X_scaled[y == 0]

"""### **ðŸ”Ÿ Model Training**"""

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.optimizers import Adam

input_dim = X_normal.shape[1]

input_layer = Input(shape=(input_dim,))
encoded = Dense(16, activation="relu")(input_layer)
encoded = Dense(8, activation="relu")(encoded)
decoded = Dense(16, activation="relu")(encoded)
output_layer = Dense(input_dim, activation="linear")(decoded)

autoencoder = Model(input_layer, output_layer)
autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss="mse")

autoencoder.fit(
    X_normal, X_normal,
    epochs=15,
    batch_size=256,
    shuffle=True,
    validation_split=0.1,
    verbose=1
)

X_pred = autoencoder.predict(X_scaled)
mse = np.mean(np.square(X_scaled - X_pred), axis=1)

threshold = np.percentile(mse[y == 0], 95)

df["AE_Prediction"] = (mse > threshold).astype(int)
print("Threshold to use in API:", THRESHOLD)

from sklearn.metrics import classification_report

print(classification_report(y, df["AE_Prediction"]))

# autoencoder.save('autoencoder_model.h5')

# import joblib
# joblib.dump(scaler, 'scaler.pkl')

